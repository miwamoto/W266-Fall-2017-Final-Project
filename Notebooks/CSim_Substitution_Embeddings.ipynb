{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity Substitution\n",
    "`w266 Final Project: Crosslingual Word Embeddings`\n",
    "\n",
    "Instead of traning on randomly substituted words, here we'll choose the translation that is closest to the context embedding vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# general imports\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tell matplotlib not to open a new window\n",
    "%matplotlib inline\n",
    "\n",
    "# autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set base paths depending on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE = '/home/mmillervedam/Data'\n",
    "PROJ = '/home/mmillervedam/ProjectRepo'\n",
    "#PROJ = '/Users/mona/OneDrive/repos/final_proj/W266-Fall-2017-Final-Project'\n",
    "\n",
    "# raw data\n",
    "FULL_EN_ES = \"/home/miwamoto/en_es_shuf.txt\"\n",
    "FULL_EN_IT = \"/home/miwamoto/en_it_shuf.txt\"\n",
    "\n",
    "# vocabularies\n",
    "VOCAB_EN_ES = BASE + '/vocab/en_es_index.pkl'\n",
    "VOCAB_EN_IT = BASE + '/vocab/en_it_index.pkl'\n",
    "\n",
    "# panlex dicts\n",
    "PANLEX_EN_ES = BASE + '/panlex/en_es_dict.pkl'\n",
    "PANLEX_EN_IT = BASE + '/panlex/en_it_dict.pkl'\n",
    "\n",
    "# directory to save pickled embeddings\n",
    "SAVE_TO = BASE + '/embeddings'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English - Spanish\n",
    "### Load Data, Dict & Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from parsing import Corpus, BilingualVocabulary, batch_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load corpus\n",
    "en_es_data = Corpus(FULL_EN_ES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load panlex dictionary\n",
    "with open(PANLEX_EN_ES,'rb') as f:\n",
    "    en_es_translations = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load vocabulary\n",
    "en_es_vocab = BilingualVocabulary([], languages = ('en','es'))\n",
    "with open(VOCAB_EN_ES,'rb') as f:\n",
    "    en_es_vocab.load_from_index(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loaded 702982 panlex translations\n",
      "... loaded 200003 word ('en', 'es')vocabulary\n"
     ]
    }
   ],
   "source": [
    "# confirmations\n",
    "print('... loaded %s panlex translations'%(len(en_es_translations)))\n",
    "print('... loaded %s word %svocabulary'%(en_es_vocab.size,en_es_vocab.language))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... TF graph created for BiW2V model.\n",
      "... TF graph created for BiW2V training.\n",
      "... TF graph created for BiW2V validation.\n"
     ]
    }
   ],
   "source": [
    "from models import BiW2V_nn\n",
    "\n",
    "EMBEDDING_SIZE = 200\n",
    "\n",
    "# create model\n",
    "model = BiW2V_nn(bilingual_dict = en_es_translations,\n",
    "                 vocab = en_es_vocab, H = EMBEDDING_SIZE)\n",
    "\n",
    "# intialize TF graphs\n",
    "model.BuildCoreGraph()\n",
    "model.BuildTrainingGraph()\n",
    "model.BuildValidationGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "nBATCHES = 6000 # less than 1 epoch\n",
    "BATCH_SIZE = 48\n",
    "WINDOW_SIZE = 4\n",
    "MAX_EPOCHS = 5 # fail safe\n",
    "DATA_GENERATOR = batch_generator(en_es_data, en_es_vocab, BATCH_SIZE, WINDOW_SIZE, MAX_EPOCHS)\n",
    "TEST_WORDS = en_es_vocab.to_ids(['en_the','en_last', 'es_mundo', 'es_real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Model Initialized\n",
      "\t <tf.Variable 'Embedding_Layer/ContextEmbeddings:0' shape=(200003, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'Hidden_Layer/WordEmbeddings:0' shape=(200003, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'Hidden_Layer/b:0' shape=(200003,) dtype=float32_ref>\n",
      "... Starting Training\n",
      "... STEP 0 : Average Loss : 0.0226768477758\n",
      "   [en_the] closest:  en_vestry, en_villager, es_kraus, es_casarla, es_gangrena, es_monofisita, es_valaco, en_doubleheader,\n",
      "   [en_last] closest:  es_djokovic, en_0-14, en_katakana, es_sentimiento, en_conceptualized, es_pretendidamente, en_scar, en_8,500,\n",
      "   [es_mundo] closest:  en_sequestered, es_castrillo, en_hitoshi, en_woodroffe, es_,...), en_deeply, es_reivindicaciones, en_behring,\n",
      "   [es_real] closest:  en_isidor, en_1010, es_barbudo, en_pass, es_bandurria, en_thermopylae, en_domains, en_interpreted,\n",
      "... STEP 600 : Average Loss : 7.83098859429\n",
      "... STEP 1200 : Average Loss : 6.52981234233\n",
      "   [en_the] closest:  <s>, es_de, en_,, es_gangrena, es_,, en_vestry, es_insaciable, es_y,\n",
      "   [en_last] closest:  es_djokovic, en_0-14, en_katakana, es_sentimiento, en_conceptualized, es_pretendidamente, en_scar, en_8,500,\n",
      "   [es_mundo] closest:  en_sequestered, es_castrillo, en_hitoshi, en_woodroffe, es_,...), en_deeply, es_reivindicaciones, en_pyridine,\n",
      "   [es_real] closest:  en_isidor, en_pass, en_1010, es_barbudo, es_bandurria, en_domains, en_thermopylae, en_interpreted,\n",
      "... STEP 1800 : Average Loss : 6.10979199767\n",
      "... STEP 2400 : Average Loss : 5.78656934937\n",
      "   [en_the] closest:  <s>, en_,, es_de, es_,, es_y, en_and, <unk>, </s>,\n",
      "   [en_last] closest:  es_djokovic, en_0-14, en_katakana, es_sentimiento, en_conceptualized, es_pretendidamente, en_scar, en_8,500,\n",
      "   [es_mundo] closest:  en_sequestered, es_castrillo, en_hitoshi, en_woodroffe, es_,...), en_deeply, es_reivindicaciones, en_pyridine,\n",
      "   [es_real] closest:  en_isidor, en_pass, en_1010, es_barbudo, en_domains, es_bandurria, en_interpreted, en_thermopylae,\n",
      "... STEP 3000 : Average Loss : 5.7022045362\n",
      "... STEP 3600 : Average Loss : 5.49131373088\n",
      "   [en_the] closest:  en_,, es_de, <s>, es_,, en_and, <unk>, es_y, </s>,\n",
      "   [en_last] closest:  es_djokovic, en_0-14, en_katakana, es_sentimiento, en_conceptualized, es_pretendidamente, en_scar, en_8,500,\n",
      "   [es_mundo] closest:  en_sequestered, es_castrillo, en_hitoshi, en_woodroffe, es_,...), en_deeply, es_reivindicaciones, en_pyridine,\n",
      "   [es_real] closest:  en_isidor, en_pass, es_barbudo, en_1010, en_domains, es_bandurria, en_interpreted, en_thermopylae,\n",
      "... STEP 4200 : Average Loss : 5.42303216219\n",
      "... STEP 4800 : Average Loss : 5.30811617136\n",
      "   [en_the] closest:  en_,, es_de, <s>, en_and, es_,, en_., en_of, en_in,\n",
      "   [en_last] closest:  es_djokovic, en_0-14, en_katakana, es_sentimiento, en_conceptualized, es_pretendidamente, en_scar, en_8,500,\n",
      "   [es_mundo] closest:  en_sequestered, es_castrillo, en_hitoshi, en_woodroffe, es_,...), en_deeply, es_reivindicaciones, en_pyridine,\n",
      "   [es_real] closest:  en_isidor, en_pass, es_barbudo, en_1010, en_domains, en_interpreted, es_bandurria, en_betul,\n",
      "... STEP 5400 : Average Loss : 5.18039214055\n",
      "... STEP 6000 : Average Loss : 5.05663639072\n",
      "   [en_the] closest:  en_,, es_de, en_and, <s>, en_., es_,, en_in, en_a,\n",
      "   [en_last] closest:  es_djokovic, en_0-14, en_katakana, en_conceptualized, es_sentimiento, es_pretendidamente, en_scar, en_8,500,\n",
      "   [es_mundo] closest:  en_sequestered, es_castrillo, en_hitoshi, en_woodroffe, es_,...), en_deeply, es_reivindicaciones, en_forscene,\n",
      "   [es_real] closest:  en_isidor, en_pass, es_barbudo, en_1010, es_del, en_domains, en_interpreted, es_bandurria,\n",
      "... Training Complete\n",
      "... 6000 batches trained in 5380.98421979 seconds\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "start = time.time()\n",
    "model.train(nBATCHES, DATA_GENERATOR, TEST_WORDS, learning_rate = 0.5)\n",
    "tot = (time.time() - start)\n",
    "print('... {} batches trained in {} seconds'.format(nBATCHES, tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Bu Hao` (a.k.a. `Bad News Bears` a.k.a `Yoku Nai`)\n",
    "```\n",
    "... 1000 batches trained in 553.925096989 seconds\n",
    "... 6000 batches trained in 5380.98421979 seconds\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Embeddings such as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context \n",
    "filename = SAVE_TO + '/en_es_nn_6K_cw4_V_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model.context_embeddings, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# word\n",
    "filename = SAVE_TO + '/en_es_nn_600K_cw4_U_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model.word_embeddings, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
