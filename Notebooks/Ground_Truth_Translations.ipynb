{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth Translations\n",
    "#### Exploration and Accuracy Calculation\n",
    "w266 Final Project: Crosslingual Word Embeddings\n",
    "\n",
    "Created: 2017-12-10 RLH\n",
    "\n",
    "Updated: 2017-12-19 RLH\n",
    "\n",
    "\n",
    "In this notebook I'm exploring the format of the ground-truth translations from MUSE (linked in BaselineModels/data) and writing a function to take the embeddings for a particular language and calculate accuracy, as defined in Vulic and Moens (2015)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys  \n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import datetime as dt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# tell matplotlib not to open a new window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filepaths\n",
    "BASE = '/home/rhopper/W266-Fall-2017-Final-Project/BaselineModels/data/ground_truth_translations'\n",
    "FPATH_ENES = BASE + '/en-es.txt' # English -> Spanish\n",
    "FPATH_ENIT = BASE + '/en-it.txt' # English -> Italian\n",
    "FPATH_ENNL = BASE + '/en-nl.txt' # English -> Dutch\n",
    "FPATH_ENJA = BASE + '/en-ja.txt' # English -> Japanese\n",
    "FPATH_ESEN = BASE + '/es-en.txt' \n",
    "FPATH_ITEN = BASE + '/it-en.txt' \n",
    "FPATH_NLEN = BASE + '/nl-en.txt'\n",
    "FPATH_JAEN = BASE + '/ja-en.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>112579</td>\n",
       "      <td>112579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>93083</td>\n",
       "      <td>96614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>sing</td>\n",
       "      <td>angustia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            en        es\n",
       "count   112579    112579\n",
       "unique   93083     96614\n",
       "top       sing  angustia\n",
       "freq         6         6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll explore the English to Spanish file to get a feel for it\n",
    "en_es = pd.read_csv(FPATH_ENES, sep=\" \", header=None)\n",
    "en_es.columns = [\"en\", \"es\"]\n",
    "en_es.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the idea of \"ground truth\" is complicated by the fact that some words have multiple equally-valid translations (e.g. \"the\").\n",
    "\n",
    "I assume that in terms of accuracy, it counts as \"accurate\" if \"the\" is translated into any of the possible translations (in the context of this task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>el</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>los</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    en   es\n",
       "0  the   el\n",
       "1  the  las\n",
       "2  the  los\n",
       "3  the   la\n",
       "4  and    y"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_es.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f03c9e6b210>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f03c74de2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#How many words have more than one translation?\n",
    "en_translation_counts = en_es.groupby(by='en').size()\n",
    "en_translation_counts[en_translation_counts > 1].hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like these ground-truth translations also contain some odd values (like hex codes and text speak - \"lmfao\" appears).\n",
    "\n",
    "In other circumstances I might want to strip out these odd translations but I don't think they will affect our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 81020 unique words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "en\n",
       "nostra         1\n",
       "breakbeat      1\n",
       "ruthenians     1\n",
       "burstyn        1\n",
       "lanterne       1\n",
       "temples        1\n",
       "tineo          1\n",
       "audits         1\n",
       "tecumseh       1\n",
       "cotoneaster    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looks like a lot of proper nouns\n",
    "\n",
    "inflex_words = en_translation_counts[en_translation_counts < 2]\n",
    "print(\"Total: {} unique words\".format(len(inflex_words)))\n",
    "inflex_words.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepending the tokens for easier comparison\n",
    "\n",
    "Words in the corpora have a two-letter prefix that identifies the language they belong to. We need to make this edit to the languages in the ground-truth translations for easier comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process English/Spanish files and prepend the respective languages\n",
    "#Write prepended file out\n",
    "en_es = pd.read_csv(FPATH_ENES, sep=\" \", names=[\"en\", \"es\"], header=None)\n",
    "en_es['en'] = 'en_' + en_es['en'].astype(str)\n",
    "en_es['es'] = 'es_' + en_es['es'].astype(str)\n",
    "en_es.to_csv(BASE + '/en-es-clean.csv', index=None, sep=' ', mode='a')\n",
    "\n",
    "es_en = pd.read_csv(FPATH_ESEN, sep=\" \", names=[\"es\", \"en\"], header=None)\n",
    "es_en['es'] = 'es_' + es_en['es'].astype(str)\n",
    "es_en['en'] = 'en_' + es_en['en'].astype(str)\n",
    "es_en.to_csv(BASE + '/es-en-clean.csv', index=None, sep=' ', mode='a')\n",
    "\n",
    "#Process English/Italian files and prepend the respective languages\n",
    "#Write prepended file out\n",
    "en_it = pd.read_csv(FPATH_ENIT, sep=\" \", names=[\"en\", \"it\"], header=None)\n",
    "en_it['en'] = 'en_' + en_it['en'].astype(str)\n",
    "en_it['it'] = 'it_' + en_it['it'].astype(str)\n",
    "en_it.to_csv(BASE + '/en-it-clean.csv', index=None, sep=' ', mode='a')\n",
    "\n",
    "it_en = pd.read_csv(FPATH_ITEN, sep=\" \", names=[\"it\", \"en\"], header=None)\n",
    "it_en['it'] = 'it_' + it_en['it'].astype(str)\n",
    "it_en['en'] = 'en_' + it_en['en'].astype(str)\n",
    "it_en.to_csv(BASE + '/it-en-clean.csv', index=None, sep=' ', mode='a')\n",
    "\n",
    "#Process English/Dutch files and prepend the respective languages\n",
    "#Write prepended file out\n",
    "en_nl = pd.read_csv(FPATH_ENNL, sep=\" \", names=[\"en\", \"nl\"], header=None)\n",
    "en_nl['en'] = 'en_' + en_nl['en'].astype(str)\n",
    "en_nl['nl'] = 'nl_' + en_nl['nl'].astype(str)\n",
    "en_nl.to_csv(BASE + '/en-nl-clean.csv', index=None, sep=' ', mode='a')\n",
    "\n",
    "nl_en = pd.read_csv(FPATH_NLEN, sep=\" \", names=[\"nl\", \"en\"], header=None)\n",
    "nl_en['nl'] = 'nl_' + nl_en['nl'].astype(str)\n",
    "nl_en['en'] = 'en_' + nl_en['en'].astype(str)\n",
    "nl_en.to_csv(BASE + '/nl-en-clean.csv', index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Process English/Japanese files and prepend the respective languages\n",
    "#Remove \t symbol in En/Ja files...\n",
    "\n",
    "#Write prepended file out\n",
    "en_ja = pd.read_csv(FPATH_ENJA, sep=\"\\t\", names=[\"en\", \"ja\"], header=None)\n",
    "en_ja['en'] = 'en_' + en_ja['en'].astype(str)\n",
    "en_ja['ja'] = 'ja_' + en_ja['ja'].astype(str)\n",
    "en_ja.to_csv(BASE + '/en-ja-clean.csv', index=None, sep=' ', mode='a')\n",
    "\n",
    "ja_en = pd.read_csv(FPATH_JAEN, sep=\"\\t\", names=[\"ja\", \"en\"], header=None)\n",
    "ja_en['ja'] = 'ja_' + ja_en['ja'].astype(str)\n",
    "ja_en['en'] = 'en_' + ja_en['en'].astype(str)\n",
    "ja_en.to_csv(BASE + '/ja-en-clean.csv', index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ja</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ja_から</td>\n",
       "      <td>en_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ja_として</td>\n",
       "      <td>en_as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ja_日本</td>\n",
       "      <td>en_japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ja_日本</td>\n",
       "      <td>en_nippon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ja_この</td>\n",
       "      <td>en_this</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ja         en\n",
       "0   ja_から    en_from\n",
       "1  ja_として      en_as\n",
       "2   ja_日本   en_japan\n",
       "3   ja_日本  en_nippon\n",
       "4   ja_この    en_this"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_en= pd.read_csv(BASE + \"/ja-en-clean.csv\", sep=\" \")\n",
    "ja_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating accuracy for a predicted translation\n",
    "\n",
    "We want $Acc_{1}$ from Vulic and Moens 2015: the number of source language words from ground truth translation pairs for which the top-ranked word cross-lingually is the correct translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en_the</td>\n",
       "      <td>es_el</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en_the</td>\n",
       "      <td>es_las</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en_the</td>\n",
       "      <td>es_los</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en_the</td>\n",
       "      <td>es_la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en_and</td>\n",
       "      <td>es_y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       en      es\n",
       "0  en_the   es_el\n",
       "1  en_the  es_las\n",
       "2  en_the  es_los\n",
       "3  en_the   es_la\n",
       "4  en_and    es_y"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_es = pd.read_csv(BASE + \"/en-es-clean.txt\", sep=\" \")\n",
    "en_es.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is an example of the way evaluate_prediction will fit into model1.py\n",
    "\n",
    "#We want to be able to control the verbose printing, but also to calculate accuracy whether verbose=True or not\n",
    "#We can worry about the verbose issue later\n",
    "\n",
    "if verbose and step % sim_logging_interval == 0:\n",
    "    sim = self.similarity.eval()\n",
    "    bli = self.evaluate_prediction()\n",
    "    total_valid=[] #Track the total number of valid translations in the nearest k\n",
    "    any_valid=[] #Track whether ANY of the nearest k were valid translations\n",
    "    for i in xrange(len(sample)):\n",
    "        word = index[sample[i]]\n",
    "        top_k = 3  # number of nearest neighbors\n",
    "        nearest, valid_translation = bli(source_lang, target_lang, top_k, word)\n",
    "        total_valid.append(valid_translation)\n",
    "        log_str = '   Nearest to %s:' % word\n",
    "        for k in xrange(top_k):\n",
    "            nbr = index[nearest[k]]\n",
    "            log_str = '%s %s,' % (log_str, nbr)\n",
    "        print(log_str)\n",
    "    \n",
    "    #For any_valid, we need 0/1 to calculate the mean\n",
    "    for s in range(len(total_valid)):\n",
    "        if total_valid[s] > 0:\n",
    "            any_valid.append(1)\n",
    "        else:\n",
    "            any_valid.append(0)\n",
    "    accuracy = (sum(any_valid) / (len(any_valid)))\n",
    "    print('Successful translation rate: %d' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_prediction(source_lang, target_lang, top_k, word):\n",
    "    \"\"\"\n",
    "    Given example source words and the ground truth translations, \n",
    "    evaluate the number of source language words for which one of the top three predictions is the correct translation\n",
    "    (fuzzy measure adopted from stricter Vulic and Moens task which requires that one predicted translation is exactly correct)\n",
    "    \n",
    "    Takes:\n",
    "    source_lang: a two-letter string representing the source language\n",
    "    target_lang: a two-letter string representing the target language\n",
    "    top_k: the number of predictions we're checking for in the ground truth list\n",
    "    word: the word we are interested in evaluating\n",
    "    \n",
    "    Returns:\n",
    "    nearest: the top_k nearest neighbors of word\n",
    "    valid_translation: tracks how many words in \"nearest\" are valid translations \n",
    "        (range 0-k, restricted by the number of translations in the ground truth list)\n",
    "    \"\"\"\n",
    "        \n",
    "    GTT_BASE = '/home/rhopper/W266-Fall-2017-Final-Project/BaselineModels/data/ground_truth_translations/' #'/home/mmillervedam/ProjectRepo/BaselineModels/data/ground_truth_translations/'\n",
    "    GTT_PATH = GTT_BASE + \"%s-%s-clean.txt\" % (source_lang, target_lang)\n",
    "    gtt = pd.read_csv(GTT_PATH, names = [source_lang, target_lang], sep=\" \", header=None)\n",
    "    \n",
    "    \n",
    "    valid_translation=0\n",
    "    nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "    for k in range(top_k):\n",
    "        close_word = reverse_dictionary[nearest[k]]\n",
    "        total_translations = (gtt[gtt[source_lang] == word])\n",
    "        if close_word in total_translations[total_translations.columns[1]].values:\n",
    "            valid_translation+=1\n",
    "        else:\n",
    "            valid_translation+=0\n",
    "                \n",
    "    return nearest, valid_translation    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('es_necesito', 'es_necesidad', 'es_manzano'), 2)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Revised version for testing\n",
    "def evaluate_prediction_rev(source_lang, target_lang, nearest, top_k, word):\n",
    "\n",
    "    GTT_BASE = '/home/rhopper/W266-Fall-2017-Final-Project/BaselineModels/data/ground_truth_translations/' #'/home/mmillervedam/ProjectRepo/BaselineModels/data/ground_truth_translations/'\n",
    "    GTT_PATH = GTT_BASE + \"%s-%s-clean.txt\" % (source_lang, target_lang)\n",
    "    gtt = pd.read_csv(GTT_PATH, names = [source_lang, target_lang], sep=\" \", header=None)\n",
    "    \n",
    "    valid_translation=0\n",
    "    #nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "    for k in range(top_k):\n",
    "        #close_word = reverse_dictionary[nearest[k]]\n",
    "        close_word = nearest[k]\n",
    "        total_translations = (gtt[gtt[source_lang] == word])\n",
    "        if close_word in total_translations[total_translations.columns[1]].values:\n",
    "            valid_translation+=1\n",
    "        else:\n",
    "            valid_translation+=0\n",
    "                \n",
    "    return nearest, valid_translation    \n",
    "\n",
    "\n",
    "source = \"en\"\n",
    "target = \"es\"\n",
    "nearest = ('es_pajaro', 'es_aves', 'es_ave')\n",
    "word=\"en_bird\"\n",
    "\n",
    "evaluate_prediction_rev(source, target, nearest, 3, word)\n",
    "\n",
    "\n",
    "source = \"en\"\n",
    "target = \"es\"\n",
    "nearest = ('es_necesito', 'es_necesidad', 'es_manzano')\n",
    "word=\"en_need\"\n",
    "evaluate_prediction_rev(source, target, nearest, 3, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###OLD VERSION BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bird': ('pajaro', 'aves', 'ave'),\n",
       " 'cat': ('gato', 'elefante', 'perro'),\n",
       " 'display': ('pantalla', 'mostrar', 'espectaculo'),\n",
       " 'need': ('mar', 'comer', 'barba')}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a fake dataset to test on\n",
    "valid_words = ['need', 'cat', 'bird', 'display']\n",
    "\n",
    "eval_words={}\n",
    "eval_words[\"need\"] = ('mar', 'comer', 'barba') #0/3 correct\n",
    "eval_words[\"cat\"] = ('gato', 'elefante', 'perro') #1/3 correct\n",
    "eval_words[\"display\"] = ('pantalla', 'mostrar', 'espectaculo') #2/3 correct\n",
    "eval_words[\"bird\"] = ('pajaro', 'aves', 'ave') #3/3 correct\n",
    "\n",
    "eval_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_translation(source_lang, target_lang, sample):\n",
    "    \"\"\"\n",
    "    Given example source words and the ground truth translations, \n",
    "    evaluate the number of source language words for which one of the top three predictions is the correct translation\n",
    "    (fuzzy measure adopted from stricter Vulic and Moens task which requires that one predicted translation is exactly correct)\n",
    "    \n",
    "    source_lang: a two-letter string representing the source language\n",
    "    target_lang: a two-letter string representing the target language\n",
    "    sample: the words we are interested in evaluating\n",
    "    \"\"\"\n",
    "        \n",
    "    BASE = '/home/rhopper/W266-Fall-2017-Final-Project/BaselineModels/data/ground_truth_translations/'\n",
    "    PATH = BASE + \"%s-%s-clean.txt\" % (source_lang, target_lang)\n",
    "    gtt = pd.read_csv(PATH, names = [source_lang, target_lang], sep=\" \", header=None)\n",
    "    \n",
    "    success=[]\n",
    "    for i in xrange(len(sample)):\n",
    "        word = index[sample[i]]\n",
    "        top_k = 3  # number of nearest neighbors\n",
    "        nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "        for k in range(top_k):\n",
    "            close_word = reverse_dictionary[nearest[k]] \n",
    "            total_translations = (gtt[gtt[source_lang] == word])\n",
    "            if close_word in total_translations[total_translations.columns[1]]:\n",
    "                success.append(1)\n",
    "            else:\n",
    "                success.append(0)\n",
    "                \n",
    "    return success    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006         need\n",
      "1007    necesitar\n",
      "1008     necesito\n",
      "1009     necesita\n",
      "1010    necesidad\n",
      "Name: es, dtype: object\n",
      "1006         need\n",
      "1007    necesitar\n",
      "1008     necesito\n",
      "1009     necesita\n",
      "1010    necesidad\n",
      "Name: es, dtype: object\n",
      "1006         need\n",
      "1007    necesitar\n",
      "1008     necesito\n",
      "1009     necesita\n",
      "1010    necesidad\n",
      "Name: es, dtype: object\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy('en', 'es', examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
