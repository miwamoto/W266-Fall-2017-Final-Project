{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English - Dutch Embeddings (3 versions)\n",
    "`w266 Final Project: Crosslingual Word Embeddings`\n",
    "\n",
    "Instead of traning on randomly substituted words, here we'll choose the translation that is closest to the context embedding vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tell matplotlib not to open a new window\n",
    "%matplotlib inline\n",
    "\n",
    "# autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Base Paths__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MV_BASE = '/home/mmillervedam/Data'\n",
    "MI_BASE = '/home/miwamoto/Data'\n",
    "PROJ = '/home/mmillervedam/ProjectRepo'\n",
    "#PROJ = '/Users/mona/OneDrive/repos/final_proj/W266-Fall-2017-Final-Project'\n",
    "GTT_BASE = PROJ + '/BaselineModels/data/ground_truth_translations/'\n",
    "\n",
    "# directory to save pickled embeddings\n",
    "SAVE_TO = MV_BASE + '/embeddings'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Globals__ - _the parameters below fully determine all 3 models in this NB_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "LANG = ('en','nl')\n",
    "FULL_TEXT = \"/home/miwamoto/en_nl_shuf.txt\"\n",
    "VOCAB_INDEX = MV_BASE + '/vocab/en_nl_small.pkl'\n",
    "PANLEX = MI_BASE + '/panlex/en_nl_dict.pkl'\n",
    "GTT_PATH = GTT_BASE + \"%s-%s-clean.csv\" % (LANG[1], LANG[0])\n",
    "\n",
    "# Model\n",
    "EMBEDDING_SIZE = 200\n",
    "\n",
    "# Training\n",
    "nBATCHES = 100000 # <<< 1 epoch with our 1 million sentence corpus\n",
    "BATCH_SIZE = 48\n",
    "WINDOW_SIZE = 4\n",
    "MAX_EPOCHS = 5 # fail safe\n",
    "ALPHA = 0.5 # authors use a much smaller learning rate but train longer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from parsing import Corpus, BilingualVocabulary, batch_generator, get_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load corpus\n",
    "raw_data = Corpus(FULL_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load panlex dictionary\n",
    "with open(PANLEX,'rb') as f:\n",
    "    translations = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vocabulary\n",
    "vocab = BilingualVocabulary([], languages = LANG)\n",
    "with open(VOCAB_INDEX,'rb') as f:\n",
    "    vocab.load_from_index(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loaded 437931 panlex translations\n",
      "... loaded 20003 word ('en', 'nl') vocabulary\n"
     ]
    }
   ],
   "source": [
    "# confirmations\n",
    "print('... loaded %s panlex translations'%(len(translations)))\n",
    "print('... loaded %s word %s vocabulary'%(vocab.size,vocab.language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... test word ids: [3, 226, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "# Validation Words (for training printout)\n",
    "TEST_WORDS = vocab.to_ids(['en_the','en_last', 'nl_voor', 'nl_aantal'])\n",
    "print('... test word ids:', TEST_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loaded 93854 ground truth translations.\n"
     ]
    }
   ],
   "source": [
    "# Ground Truth Translations\n",
    "GTT_DF = pd.read_csv(GTT_PATH, names = [LANG[1], LANG[0]], sep=' ', header=None)\n",
    "print('... loaded %s ground truth translations.'%(len(GTT_DF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loaded 0 evaluation words.\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Words (for reporting recall)\n",
    "eval_words = [w for w in get_common_words(vocab) if w.startswith(LANG[1])]\n",
    "EVAL_IDS = vocab.to_ids(eval_words)\n",
    "print('... loaded %s evaluation words.' % (len(EVAL_IDS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: Random Translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BiW2V_random\n",
    "\n",
    "# create model\n",
    "model_1 = BiW2V_random(bilingual_dict = translations,\n",
    "                       vocab = vocab, H = EMBEDDING_SIZE)\n",
    "\n",
    "# intialize TF graphs\n",
    "model_1.BuildCoreGraph()\n",
    "model_1.BuildTrainingGraph()\n",
    "model_1.BuildValidationGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fresh data generator\n",
    "DATA_GENERATOR = batch_generator(raw_data, vocab, BATCH_SIZE, WINDOW_SIZE, MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "start = time.time()\n",
    "model_1.train(nBATCHES, DATA_GENERATOR, TEST_WORDS, learning_rate = ALPHA)\n",
    "tot = (time.time() - start)\n",
    "print('... {} batches trained in {} seconds'.format(nBATCHES, tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# context \n",
    "filename = SAVE_TO + '/en_es_rand_100K_V_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_1.context_embeddings, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# word\n",
    "filename = SAVE_TO + '/en_es_rand_100K_U_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_1.word_embeddings, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: Most Common Target Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BiW2V_mle\n",
    "\n",
    "# create model\n",
    "model_2 = BiW2V_mle(bilingual_dict = translations,\n",
    "                       vocab = vocab, H = EMBEDDING_SIZE)\n",
    "\n",
    "# intialize TF graphs\n",
    "model_2.BuildCoreGraph()\n",
    "model_2.BuildTrainingGraph()\n",
    "model_2.BuildValidationGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fresh data generator\n",
    "DATA_GENERATOR = batch_generator(raw_data, vocab, BATCH_SIZE, WINDOW_SIZE, MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "start = time.time()\n",
    "model_2.train(nBATCHES, DATA_GENERATOR, TEST_WORDS, learning_rate = ALPHA)\n",
    "tot = (time.time() - start)\n",
    "print('... {} batches trained in {} seconds'.format(nBATCHES, tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# context \n",
    "filename = SAVE_TO + '/en_es_mle_100K_V_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_2.context_embeddings, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# word\n",
    "filename = SAVE_TO + '/en_es_mle_100K_U_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_2.word_embeddings, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3: Closest Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BiW2V_nn\n",
    "\n",
    "# create model\n",
    "model_3 = BiW2V_nn(bilingual_dict = translations,\n",
    "                   vocab = vocab, H = EMBEDDING_SIZE)\n",
    "\n",
    "# intialize TF graphs\n",
    "model_3.BuildCoreGraph()\n",
    "model_3.BuildTrainingGraph()\n",
    "model_3.BuildValidationGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fresh data generator\n",
    "DATA_GENERATOR = batch_generator(raw_data, vocab, BATCH_SIZE, WINDOW_SIZE, MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "nBATCHES = 5000 # Takes too long w/ nn so we'll only do 5K\n",
    "start = time.time()\n",
    "model_3.train(nBATCHES, DATA_GENERATOR, TEST_WORDS, learning_rate = ALPHA)\n",
    "tot = (time.time() - start)\n",
    "print('... {} batches trained in {} seconds'.format(nBATCHES, tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# context \n",
    "filename = SAVE_TO + '/en_es_nn_5K_V_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_2.context_embeddings, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# word\n",
    "filename = SAVE_TO + '/en_es_nn_5K_U_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_2.word_embeddings, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
