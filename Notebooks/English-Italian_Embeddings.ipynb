{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English - Italian Embeddings (3 versions)\n",
    "`w266 Final Project: Crosslingual Word Embeddings`\n",
    "\n",
    "Instead of traning on randomly substituted words, here we'll choose the translation that is closest to the context embedding vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# general imports\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tell matplotlib not to open a new window\n",
    "%matplotlib inline\n",
    "\n",
    "# autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Base Paths__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE = '/home/mmillervedam/Data'\n",
    "PROJ = '/home/mmillervedam/ProjectRepo'\n",
    "GTT_BASE = PROJ + '/BaselineModels/data/ground_truth_translations/'\n",
    "#PROJ = '/Users/mona/OneDrive/repos/final_proj/W266-Fall-2017-Final-Project'\n",
    "\n",
    "# directory to save pickled embeddings\n",
    "SAVE_TO = BASE + '/embeddings'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Globals__ - _the parameters below fully determine all 3 models in this NB_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "LANG = ('en','it')\n",
    "FULL_TEXT = \"/home/miwamoto/en_it_shuf.txt\"\n",
    "VOCAB_INDEX = BASE + '/vocab/en_it_small.pkl'\n",
    "PANLEX = BASE + '/panlex/en_it_dict.pkl'\n",
    "GTT_PATH = GTT_BASE + \"%s-%s-clean.csv\" % (LANG[1], LANG[0])\n",
    "\n",
    "# Model\n",
    "EMBEDDING_SIZE = 200\n",
    "\n",
    "# Training\n",
    "nBATCHES = 50000 # <<< 1 epoch with our 1 million sentence corpus\n",
    "BATCH_SIZE = 48\n",
    "WINDOW_SIZE = 4\n",
    "MAX_EPOCHS = 5 # fail safe\n",
    "ALPHA = 0.5 # authors use a much smaller learning rate but train longer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from parsing import Corpus, BilingualVocabulary, batch_generator, get_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corpus\n",
    "raw_data = Corpus(FULL_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load panlex dictionary\n",
    "with open(PANLEX,'rb') as f:\n",
    "    translations = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load vocabulary\n",
    "vocab = BilingualVocabulary([], languages = LANG)\n",
    "with open(VOCAB_INDEX,'rb') as f:\n",
    "    vocab.load_from_index(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loaded 525091 panlex translations\n",
      "... loaded 20003 word ('en', 'it') vocabulary\n"
     ]
    }
   ],
   "source": [
    "# confirmations\n",
    "print('... loaded %s panlex translations'%(len(translations)))\n",
    "print('... loaded %s word %s vocabulary'%(vocab.size,vocab.language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... test word ids: [3, 239, 10020, 10040]\n"
     ]
    }
   ],
   "source": [
    "# Validation Words (for training printout)\n",
    "TEST_WORDS = vocab.to_ids(['en_the','en_last', 'it_si', 'it_suo'])\n",
    "print('... test word ids:', TEST_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loaded 103613 ground truth translations.\n"
     ]
    }
   ],
   "source": [
    "# Ground Truth Translations\n",
    "gtt_df = pd.read_csv(GTT_PATH, names = [LANG[1], LANG[0]], sep=' ', header=None)\n",
    "print('... loaded %s ground truth translations.'%(len(GTT_DF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loaded 8516 evaluation words.\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Words (for reporting recall)\n",
    "eval_words = [w for w in get_common_words(vocab) if w.startswith(LANG[1])]\n",
    "EVAL_IDS = vocab.to_ids(eval_words)\n",
    "print('... loaded %s evaluation words.' % (len(EVAL_IDS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: Random Translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... TF graph created for BiW2V model.\n",
      "... TF graph created for BiW2V training.\n",
      "... TF graph created for BiW2V validation.\n"
     ]
    }
   ],
   "source": [
    "from models import BiW2V_random\n",
    "\n",
    "# create model\n",
    "model_1 = BiW2V_random(bilingual_dict = translations,\n",
    "                       vocab = vocab, H = EMBEDDING_SIZE)\n",
    "\n",
    "# intialize TF graphs\n",
    "model_1.BuildCoreGraph()\n",
    "model_1.BuildTrainingGraph()\n",
    "model_1.BuildValidationGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fresh data generator\n",
    "DATA_GENERATOR = batch_generator(raw_data, vocab, BATCH_SIZE, WINDOW_SIZE, MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Model Initialized\n",
      "\t <tf.Variable 'Embedding_Layer/ContextEmbeddings:0' shape=(20003, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'Hidden_Layer/WordEmbeddings:0' shape=(20003, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'Hidden_Layer/b:0' shape=(20003,) dtype=float32_ref>\n",
      "... Starting Training\n",
      "... STEP 0 : Average Loss : 0.000264484786987\n",
      "   [en_the] closest:  it_cristina, en_commented, it_sacerdotale, it_amiga, it_vantaggio, en_muhammad, it_gemello, it_esistente,\n",
      "   [en_last] closest:  en_n, en_ridge, it_kg, it_cancellare, it_professionistico, en_quad, it_consentire, it_arti,\n",
      "   [it_si] closest:  it_compiti, it_limitazione, en_sculptor, en_switching, en_solidarity, en_hereford, it_u, it_pesante,\n",
      "   [it_suo] closest:  it_abitanti, it_presentarsi, en_convert, en_regulate, it_notazione, en_son-in-law, it_compresa, it_girone,\n",
      "... STEP 50000 : Average Loss : 4.10927392767\n",
      "... STEP 100000 : Average Loss : 3.85516811703\n",
      "   [en_the] closest:  en_a, en_its, en_an, en_one, en_his, it_la, it_riunirsi, it_della,\n",
      "   [en_last] closest:  en_quad, it_consentire, en_n, it_salone, it_arti, it_professionistico, en_ridge, en_she,\n",
      "   [it_si] closest:  it_delle, it_settanta, en_acclaim, it_gli, it_ripetutamente, it_visconti, en_ion, it_materia,\n",
      "   [it_suo] closest:  it_abitanti, it_del, it_il, en_convert, en_be, it_rito, it_presentarsi, en_landscape,\n",
      "... STEP 150000 : Average Loss : 3.77276867841\n",
      "... STEP 200000 : Average Loss : 3.71266719249\n",
      "   [en_the] closest:  en_a, en_its, en_an, en_his, en_their, en_this, en_one, it_della,\n",
      "   [en_last] closest:  en_league, en_quad, en_after, it_professionistico, en_economist, it_arti, it_consentire, it_cancellare,\n",
      "   [it_si] closest:  it_delle, it_ripetutamente, it_visconti, it_settanta, it_le, it_gli, it_reliquia, en_acclaim,\n",
      "   [it_suo] closest:  it_un, it_il, it_del, it_abitanti, it_rito, en_convert, it_fu, en_landscape,\n",
      "... STEP 250000 : Average Loss : 3.66867491206\n",
      "... STEP 300000 : Average Loss : 3.62933794949\n",
      "   [en_the] closest:  en_its, en_a, en_an, en_this, en_their, en_his, en_one, it_della,\n",
      "   [en_last] closest:  en_after, en_league, en_final, en_before, en_until, en_first, en_quad, en_weeks,\n",
      "   [it_si] closest:  it_delle, it_ripetutamente, it_visconti, it_le, it_reliquia, en_hereford, en_ion, it_settanta,\n",
      "   [it_suo] closest:  en_his, it_un, it_rito, it_il, en_her, en_convert, it_del, it_abitanti,\n",
      "... STEP 350000 : Average Loss : 3.60212432476\n",
      "... STEP 400000 : Average Loss : 3.59838218079\n",
      "   [en_the] closest:  en_its, en_a, en_this, en_an, en_their, en_his, en_one, it_amiga,\n",
      "   [en_last] closest:  en_after, en_league, en_final, en_first, en_before, en_until, en_weeks, en_next,\n",
      "   [it_si] closest:  it_ripetutamente, it_le, it_visconti, it_delle, it_reliquia, en_hereford, it_dante, it_sulla,\n",
      "   [it_suo] closest:  en_his, en_her, it_un, it_questo, it_rito, it_proprio, it_momento, en_marketing,\n",
      "... STEP 450000 : Average Loss : 3.56207469346\n",
      "... STEP 500000 : Average Loss : 3.5358864178\n",
      "   [en_the] closest:  en_its, en_this, en_a, en_an, en_their, en_his, en_one, en_each,\n",
      "   [en_last] closest:  en_after, en_final, en_first, en_league, en_before, en_next, en_until, en_third,\n",
      "   [it_si] closest:  it_ripetutamente, it_le, it_visconti, it_delle, it_compiti, it_sulla, it_indirizzo, it_dante,\n",
      "   [it_suo] closest:  en_his, en_her, it_un, it_proprio, it_quale, it_questo, it_loro, it_rito,\n",
      "... Training Complete\n",
      "... 500000 batches trained in 1346.75051999 seconds\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "start = time.time()\n",
    "model_1.train(nBATCHES, DATA_GENERATOR, TEST_WORDS, learning_rate = ALPHA)\n",
    "tot = (time.time() - start)\n",
    "print('... {} batches trained in {} seconds'.format(nBATCHES, tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context \n",
    "filename = SAVE_TO + '/en_it_rand_500K_V_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_1.context_embeddings, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# word\n",
    "filename = SAVE_TO + '/en_it_rand_500K_U_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_1.word_embeddings, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load saved embeddings\n",
    "with open(SAVE_TO + '/en_it_rand_500K_V_dec19.pkl','rb') as f:\n",
    "    C_embedding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... C shape: (20003, 200)\n",
      "... eval IDs should be > 10003: [19065, 10679, 17158, 15613, 13376]\n",
      "... number to eval: 8516\n",
      "... GTT src language: it\n"
     ]
    }
   ],
   "source": [
    "# sanity checks\n",
    "print('... C shape:', C_embedding.shape)\n",
    "print('... eval IDs should be > 10003:', EVAL_IDS[:5])\n",
    "print('... number to eval:', len(EVAL_IDS))\n",
    "print('... GTT src language:', gtt_df.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bilingual Induction Task.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import evaluateBLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Evaluating 8516 'it' Ground Truth Translations\n",
      "... TF graph created for BiW2V model.\n",
      "... TF graph created for BiW2V validation.\n",
      "... finding neighbors.\n",
      "... Done. Total successful translation rate: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[19065, 15359, 14739, 12500, 11830],\n",
       "        [10679, 14462, 14183, 10859, 13836],\n",
       "        [17158, 10289, 10657, 14685, 16737],\n",
       "        ..., \n",
       "        [13539, 19729, 10873, 18593, 15290],\n",
       "        [15296, 10101, 19645, 17042, 16285],\n",
       "        [19768, 10548, 10093, 10720, 14907]]),\n",
       " array([[  28, 3125, 6106, 6872, 6342],\n",
       "        [8353, 8809,   10,  153, 6040],\n",
       "        [7202, 4800, 9888, 4377, 7412],\n",
       "        ..., \n",
       "        [  46, 1117, 9994,  108, 5437],\n",
       "        [ 157, 8692, 6712,  593, 2468],\n",
       "        [ 188,  237,  155,  765, 7579]]))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_nbrs, tgt_nbrs = evaluateBLI(C_embedding, vocab, gtt_df, \n",
    "                                 EVAL_IDS, top_k = 10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: Most Common Target Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... TF graph created for BiW2V model.\n",
      "... TF graph created for BiW2V training.\n",
      "... TF graph created for BiW2V validation.\n"
     ]
    }
   ],
   "source": [
    "from models import BiW2V_mle\n",
    "\n",
    "# create model\n",
    "model_2 = BiW2V_mle(bilingual_dict = translations,\n",
    "                       vocab = vocab, H = EMBEDDING_SIZE)\n",
    "\n",
    "# intialize TF graphs\n",
    "model_2.BuildCoreGraph()\n",
    "model_2.BuildTrainingGraph()\n",
    "model_2.BuildValidationGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fresh data generator\n",
    "DATA_GENERATOR = batch_generator(raw_data, vocab, BATCH_SIZE, WINDOW_SIZE, MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Model Initialized\n",
      "\t <tf.Variable 'Embedding_Layer/ContextEmbeddings:0' shape=(20003, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'Hidden_Layer/WordEmbeddings:0' shape=(20003, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'Hidden_Layer/b:0' shape=(20003,) dtype=float32_ref>\n",
      "... Starting Training\n",
      "... STEP 0 : Average Loss : 0.00252045059204\n",
      "   [en_the] closest:  en_bern, en_mini, it_9, en_trout, en_gather, en_rival, en_homes, it_politica,\n",
      "   [en_last] closest:  it_led, en_idaho, it_funzioni, en_up, it_svevia, it_trascrizione, en_climbing, it_foto,\n",
      "   [it_si] closest:  en_6th, en_batting, en_reporter, en_shortened, it_alpini, it_tecnologie, en_addresses, en_credits,\n",
      "   [it_suo] closest:  en_overhead, en_rico, en_venice, it_provenza, it_raven, it_battezzato, it_fire, it_normativa,\n",
      "... STEP 5000 : Average Loss : 4.71148335021\n",
      "... STEP 10000 : Average Loss : 4.22817595466\n",
      "   [en_the] closest:  en_a, en_to, en_and, en_bern, en_mini, en_in, en_trout, it_politica,\n",
      "   [en_last] closest:  it_led, en_idaho, it_funzioni, en_up, it_trascrizione, it_svevia, en_climbing, it_foto,\n",
      "   [it_si] closest:  en_6th, en_reporter, it_tecnologie, en_batting, it_alpini, it_i, en_cleaning, en_cancelled,\n",
      "   [it_suo] closest:  en_overhead, en_venice, en_rico, it_fire, it_raven, it_provenza, it_niente, it_battezzato,\n",
      "... STEP 15000 : Average Loss : 4.04906350614\n",
      "... STEP 20000 : Average Loss : 4.0758832608\n",
      "   [en_the] closest:  en_a, en_to, en_and, en_in, en_bern, en_mini, en_electric, en_his,\n",
      "   [en_last] closest:  it_led, en_idaho, it_funzioni, en_up, it_svevia, it_trascrizione, it_foto, en_climbing,\n",
      "   [it_si] closest:  it_i, en_6th, en_reporter, it_tecnologie, it_alpini, en_batting, en_cancelled, en_cleaning,\n",
      "   [it_suo] closest:  en_overhead, en_venice, it_di, en_rico, it_fire, it_raven, it_provenza, it_niente,\n",
      "... STEP 25000 : Average Loss : 3.99680838432\n",
      "... STEP 30000 : Average Loss : 3.94877794099\n",
      "   [en_the] closest:  en_a, en_and, en_to, en_his, en_bern, en_in, en_an, en_its,\n",
      "   [en_last] closest:  en_idaho, it_led, it_funzioni, en_up, it_svevia, it_trascrizione, it_foto, en_climbing,\n",
      "   [it_si] closest:  it_i, en_6th, en_reporter, it_tecnologie, it_alpini, en_batting, it_in, en_cancelled,\n",
      "   [it_suo] closest:  it_di, en_overhead, en_venice, it_fire, it_raven, en_rico, it_stato, it_niente,\n",
      "... STEP 35000 : Average Loss : 3.92520805442\n",
      "... STEP 40000 : Average Loss : 3.90608162381\n",
      "   [en_the] closest:  en_a, en_his, en_and, en_its, en_an, en_in, en_bern, en_to,\n",
      "   [en_last] closest:  en_idaho, it_led, it_funzioni, en_up, it_trascrizione, it_svevia, it_foto, en_climbing,\n",
      "   [it_si] closest:  it_i, en_reporter, en_6th, it_tecnologie, it_alpini, it_in, en_batting, en_cancelled,\n",
      "   [it_suo] closest:  it_di, en_overhead, en_venice, it_dopo, it_fire, it_raven, en_rico, it_stato,\n",
      "... STEP 45000 : Average Loss : 3.88112063468\n",
      "... STEP 50000 : Average Loss : 3.82327789607\n",
      "   [en_the] closest:  en_a, en_his, en_its, en_an, en_this, en_and, en_bern, en_electric,\n",
      "   [en_last] closest:  en_idaho, it_led, it_funzioni, en_up, it_trascrizione, it_foto, it_svevia, en_climbing,\n",
      "   [it_si] closest:  it_i, en_reporter, en_6th, it_in, it_tecnologie, it_alpini, en_batting, it_le,\n",
      "   [it_suo] closest:  it_di, en_overhead, en_venice, it_dopo, it_raven, it_fire, it_stato, en_rico,\n",
      "... Training Complete\n",
      "... 50000 batches trained in 156.13361311 seconds\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "start = time.time()\n",
    "model_2.train(nBATCHES, DATA_GENERATOR, TEST_WORDS, learning_rate = ALPHA)\n",
    "tot = (time.time() - start)\n",
    "print('... {} batches trained in {} seconds'.format(nBATCHES, tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# context \n",
    "filename = SAVE_TO + '/en_it_mle_50K_V_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_2.context_embeddings, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# word\n",
    "filename = SAVE_TO + '/en_it_mle_50K_U_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_2.word_embeddings, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3: Closest Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... TF graph created for BiW2V model.\n",
      "... TF graph created for BiW2V training.\n",
      "... TF graph created for BiW2V validation.\n"
     ]
    }
   ],
   "source": [
    "from models import BiW2V_nn\n",
    "\n",
    "# create model\n",
    "model_3 = BiW2V_nn(bilingual_dict = translations,\n",
    "                   vocab = vocab, H = EMBEDDING_SIZE)\n",
    "\n",
    "# intialize TF graphs\n",
    "model_3.BuildCoreGraph()\n",
    "model_3.BuildTrainingGraph()\n",
    "model_3.BuildValidationGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fresh data generator\n",
    "DATA_GENERATOR = batch_generator(raw_data, vocab, BATCH_SIZE, WINDOW_SIZE, MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Model Initialized\n",
      "\t <tf.Variable 'Embedding_Layer/ContextEmbeddings:0' shape=(20003, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'Hidden_Layer/WordEmbeddings:0' shape=(20003, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'Hidden_Layer/b:0' shape=(20003,) dtype=float32_ref>\n",
      "... Starting Training\n",
      "... STEP 0 : Average Loss : 0.02340858078\n",
      "   [en_the] closest:  en_nutrition, it_ma, en_prolonged, it_falco, it_vercelli, en_artists, en_beliefs, it_idraulico,\n",
      "   [en_last] closest:  en_earn, en_renowned, it_decadimento, it_boy, en_korea, en_basement, en_resulting, en_told,\n",
      "   [it_si] closest:  en_qualities, it_generato, it_scuole, en_employer, en_situation, en_chorus, en_to, en_inadequate,\n",
      "   [it_suo] closest:  en_sat, it_rimpiazzare, en_playing, it_triangolare, it_realmente, en_profile, it_tutta, it_stirpe,\n",
      "... STEP 500 : Average Loss : 6.30888293695\n",
      "... STEP 1000 : Average Loss : 5.52120716763\n",
      "   [en_the] closest:  en_nutrition, en_artists, it_falco, it_ma, en_beliefs, it_saturno, it_anime, it_siccità,\n",
      "   [en_last] closest:  en_earn, en_renowned, it_decadimento, it_boy, en_korea, en_basement, en_resulting, en_told,\n",
      "   [it_si] closest:  en_qualities, it_generato, it_scuole, en_to, en_employer, en_chorus, en_situation, en_inadequate,\n",
      "   [it_suo] closest:  en_sat, it_rimpiazzare, en_playing, it_triangolare, it_realmente, it_tutta, en_profile, en_spirits,\n",
      "... STEP 1500 : Average Loss : 5.36810376883\n",
      "... STEP 2000 : Average Loss : 5.16852718353\n",
      "   [en_the] closest:  en_nutrition, en_artists, it_falco, it_ma, en_beliefs, it_saturno, it_siccità, it_anime,\n",
      "   [en_last] closest:  en_earn, en_renowned, it_decadimento, it_boy, en_korea, en_basement, en_resulting, en_told,\n",
      "   [it_si] closest:  en_qualities, it_scuole, it_generato, en_to, en_employer, en_chorus, en_situation, en_inadequate,\n",
      "   [it_suo] closest:  en_sat, it_rimpiazzare, en_playing, it_triangolare, it_tutta, it_realmente, en_profile, en_spirits,\n",
      "... STEP 2500 : Average Loss : 5.13391390038\n",
      "... STEP 3000 : Average Loss : 5.07301244187\n",
      "   [en_the] closest:  en_nutrition, en_artists, it_falco, it_ma, it_saturno, it_siccità, en_beliefs, en_bengal,\n",
      "   [en_last] closest:  en_renowned, en_earn, it_decadimento, it_boy, en_korea, en_basement, en_resulting, en_told,\n",
      "   [it_si] closest:  en_qualities, en_to, it_scuole, it_generato, en_employer, en_chorus, en_situation, en_inadequate,\n",
      "   [it_suo] closest:  en_sat, it_rimpiazzare, en_playing, it_tutta, it_triangolare, it_realmente, en_profile, en_spirits,\n",
      "... STEP 3500 : Average Loss : 5.01885948992\n",
      "... STEP 4000 : Average Loss : 5.05571406984\n",
      "   [en_the] closest:  en_nutrition, en_a, en_artists, it_falco, it_ma, it_siccità, en_bengal, it_anime,\n",
      "   [en_last] closest:  en_earn, en_renowned, it_decadimento, it_boy, en_korea, en_basement, en_resulting, en_turin,\n",
      "   [it_si] closest:  en_qualities, en_to, it_scuole, en_employer, it_generato, en_chorus, en_situation, en_inadequate,\n",
      "   [it_suo] closest:  en_sat, it_rimpiazzare, en_playing, it_tutta, it_triangolare, it_realmente, en_profile, en_spirits,\n",
      "... STEP 4500 : Average Loss : 4.97535962629\n",
      "... STEP 5000 : Average Loss : 4.9615819416\n",
      "   [en_the] closest:  en_nutrition, en_a, it_falco, en_artists, it_ma, en_bengal, it_siccità, it_anime,\n",
      "   [en_last] closest:  en_renowned, en_earn, it_decadimento, it_boy, en_korea, en_basement, en_resulting, en_turin,\n",
      "   [it_si] closest:  en_qualities, en_to, it_scuole, en_employer, it_generato, en_chorus, en_preston, it_sceso,\n",
      "   [it_suo] closest:  en_sat, it_rimpiazzare, en_playing, it_tutta, it_realmente, it_triangolare, en_profile, en_spirits,\n",
      "... Training Complete\n",
      "... 5000 batches trained in 1766.22677398 seconds\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "nBATCHES = 5000 # Takes too long w/ nn so we'll only do 5K\n",
    "start = time.time()\n",
    "model_3.train(nBATCHES, DATA_GENERATOR, TEST_WORDS, learning_rate = ALPHA)\n",
    "tot = (time.time() - start)\n",
    "print('... {} batches trained in {} seconds'.format(nBATCHES, tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# context \n",
    "filename = SAVE_TO + '/en_it_nn_5K_V_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_2.context_embeddings, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# word\n",
    "filename = SAVE_TO + '/en_it_nn_5K_U_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_2.word_embeddings, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
