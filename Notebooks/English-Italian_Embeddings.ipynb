{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English - Italian Embeddings (3 versions)\n",
    "`w266 Final Project: Crosslingual Word Embeddings`\n",
    "\n",
    "Instead of traning on randomly substituted words, here we'll choose the translation that is closest to the context embedding vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# general imports\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tell matplotlib not to open a new window\n",
    "%matplotlib inline\n",
    "\n",
    "# autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Base Paths__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE = '/home/mmillervedam/Data'\n",
    "PROJ = '/home/mmillervedam/ProjectRepo'\n",
    "GTT_BASE = PROJ + '/BaselineModels/data/ground_truth_translations/'\n",
    "#PROJ = '/Users/mona/OneDrive/repos/final_proj/W266-Fall-2017-Final-Project'\n",
    "\n",
    "# directory to save pickled embeddings\n",
    "SAVE_TO = BASE + '/embeddings'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Globals__ - _the parameters below fully determine all 3 models in this NB_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "LANG = ('en','it')\n",
    "FULL_TEXT = \"/home/miwamoto/en_it_shuf.txt\"\n",
    "VOCAB_INDEX = BASE + '/vocab/en_it_small.pkl'\n",
    "PANLEX = BASE + '/panlex/en_it_dict.pkl'\n",
    "GTT_PATH = GTT_BASE + \"%s-%s-clean.csv\" % (LANG[1], LANG[0])\n",
    "\n",
    "# Model\n",
    "EMBEDDING_SIZE = 200\n",
    "\n",
    "# Training\n",
    "nBATCHES = 50000 # <<< 1 epoch with our 1 million sentence corpus\n",
    "BATCH_SIZE = 48\n",
    "WINDOW_SIZE = 4\n",
    "MAX_EPOCHS = 5 # fail safe\n",
    "ALPHA = 0.5 # authors use a much smaller learning rate but train longer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from parsing import Corpus, BilingualVocabulary, batch_generator, get_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corpus\n",
    "raw_data = Corpus(FULL_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load panlex dictionary\n",
    "with open(PANLEX,'rb') as f:\n",
    "    translations = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load vocabulary\n",
    "vocab = BilingualVocabulary([], languages = LANG)\n",
    "with open(VOCAB_INDEX,'rb') as f:\n",
    "    vocab.load_from_index(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loaded 525091 panlex translations\n",
      "... loaded 20003 word ('en', 'it') vocabulary\n"
     ]
    }
   ],
   "source": [
    "# confirmations\n",
    "print('... loaded %s panlex translations'%(len(translations)))\n",
    "print('... loaded %s word %s vocabulary'%(vocab.size,vocab.language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... test word ids: [3, 239, 10020, 10040]\n"
     ]
    }
   ],
   "source": [
    "# Validation Words (for training printout)\n",
    "TEST_WORDS = vocab.to_ids(['en_the','en_last', 'it_si', 'it_suo'])\n",
    "print('... test word ids:', TEST_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loaded 103613 ground truth translations.\n"
     ]
    }
   ],
   "source": [
    "# Ground Truth Translations\n",
    "gtt_df = pd.read_csv(GTT_PATH, names = [LANG[1], LANG[0]], sep=' ', header=None)\n",
    "print('... loaded %s ground truth translations.'%(len(GTT_DF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loaded 8516 evaluation words.\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Words (for reporting recall)\n",
    "eval_words = [w for w in get_common_words(vocab) if w.startswith(LANG[1])]\n",
    "EVAL_IDS = vocab.to_ids(eval_words)\n",
    "print('... loaded %s evaluation words.' % (len(EVAL_IDS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: Random Translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... TF graph created for BiW2V model.\n",
      "... TF graph created for BiW2V training.\n",
      "... TF graph created for BiW2V validation.\n"
     ]
    }
   ],
   "source": [
    "from models import BiW2V_random\n",
    "\n",
    "# create model\n",
    "model_1 = BiW2V_random(bilingual_dict = translations,\n",
    "                       vocab = vocab, H = EMBEDDING_SIZE)\n",
    "\n",
    "# intialize TF graphs\n",
    "model_1.BuildCoreGraph()\n",
    "model_1.BuildTrainingGraph()\n",
    "model_1.BuildValidationGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fresh data generator\n",
    "DATA_GENERATOR = batch_generator(raw_data, vocab, BATCH_SIZE, WINDOW_SIZE, MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Model Initialized\n",
      "\t <tf.Variable 'Embedding_Layer/ContextEmbeddings:0' shape=(20003, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'Hidden_Layer/WordEmbeddings:0' shape=(20003, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'Hidden_Layer/b:0' shape=(20003,) dtype=float32_ref>\n",
      "... Starting Training\n",
      "... STEP 0 : Average Loss : 0.000264484786987\n",
      "   [en_the] closest:  it_cristina, en_commented, it_sacerdotale, it_amiga, it_vantaggio, en_muhammad, it_gemello, it_esistente,\n",
      "   [en_last] closest:  en_n, en_ridge, it_kg, it_cancellare, it_professionistico, en_quad, it_consentire, it_arti,\n",
      "   [it_si] closest:  it_compiti, it_limitazione, en_sculptor, en_switching, en_solidarity, en_hereford, it_u, it_pesante,\n",
      "   [it_suo] closest:  it_abitanti, it_presentarsi, en_convert, en_regulate, it_notazione, en_son-in-law, it_compresa, it_girone,\n",
      "... STEP 50000 : Average Loss : 4.10927392767\n",
      "... STEP 100000 : Average Loss : 3.85516811703\n",
      "   [en_the] closest:  en_a, en_its, en_an, en_one, en_his, it_la, it_riunirsi, it_della,\n",
      "   [en_last] closest:  en_quad, it_consentire, en_n, it_salone, it_arti, it_professionistico, en_ridge, en_she,\n",
      "   [it_si] closest:  it_delle, it_settanta, en_acclaim, it_gli, it_ripetutamente, it_visconti, en_ion, it_materia,\n",
      "   [it_suo] closest:  it_abitanti, it_del, it_il, en_convert, en_be, it_rito, it_presentarsi, en_landscape,\n",
      "... STEP 150000 : Average Loss : 3.77276867841\n",
      "... STEP 200000 : Average Loss : 3.71266719249\n",
      "   [en_the] closest:  en_a, en_its, en_an, en_his, en_their, en_this, en_one, it_della,\n",
      "   [en_last] closest:  en_league, en_quad, en_after, it_professionistico, en_economist, it_arti, it_consentire, it_cancellare,\n",
      "   [it_si] closest:  it_delle, it_ripetutamente, it_visconti, it_settanta, it_le, it_gli, it_reliquia, en_acclaim,\n",
      "   [it_suo] closest:  it_un, it_il, it_del, it_abitanti, it_rito, en_convert, it_fu, en_landscape,\n",
      "... STEP 250000 : Average Loss : 3.66867491206\n",
      "... STEP 300000 : Average Loss : 3.62933794949\n",
      "   [en_the] closest:  en_its, en_a, en_an, en_this, en_their, en_his, en_one, it_della,\n",
      "   [en_last] closest:  en_after, en_league, en_final, en_before, en_until, en_first, en_quad, en_weeks,\n",
      "   [it_si] closest:  it_delle, it_ripetutamente, it_visconti, it_le, it_reliquia, en_hereford, en_ion, it_settanta,\n",
      "   [it_suo] closest:  en_his, it_un, it_rito, it_il, en_her, en_convert, it_del, it_abitanti,\n",
      "... STEP 350000 : Average Loss : 3.60212432476\n",
      "... STEP 400000 : Average Loss : 3.59838218079\n",
      "   [en_the] closest:  en_its, en_a, en_this, en_an, en_their, en_his, en_one, it_amiga,\n",
      "   [en_last] closest:  en_after, en_league, en_final, en_first, en_before, en_until, en_weeks, en_next,\n",
      "   [it_si] closest:  it_ripetutamente, it_le, it_visconti, it_delle, it_reliquia, en_hereford, it_dante, it_sulla,\n",
      "   [it_suo] closest:  en_his, en_her, it_un, it_questo, it_rito, it_proprio, it_momento, en_marketing,\n",
      "... STEP 450000 : Average Loss : 3.56207469346\n",
      "... STEP 500000 : Average Loss : 3.5358864178\n",
      "   [en_the] closest:  en_its, en_this, en_a, en_an, en_their, en_his, en_one, en_each,\n",
      "   [en_last] closest:  en_after, en_final, en_first, en_league, en_before, en_next, en_until, en_third,\n",
      "   [it_si] closest:  it_ripetutamente, it_le, it_visconti, it_delle, it_compiti, it_sulla, it_indirizzo, it_dante,\n",
      "   [it_suo] closest:  en_his, en_her, it_un, it_proprio, it_quale, it_questo, it_loro, it_rito,\n",
      "... Training Complete\n",
      "... 500000 batches trained in 1346.75051999 seconds\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "start = time.time()\n",
    "model_1.train(nBATCHES, DATA_GENERATOR, TEST_WORDS, learning_rate = ALPHA)\n",
    "tot = (time.time() - start)\n",
    "print('... {} batches trained in {} seconds'.format(nBATCHES, tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context \n",
    "filename = SAVE_TO + '/en_it_rand_500K_V_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_1.context_embeddings, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# word\n",
    "filename = SAVE_TO + '/en_it_rand_500K_U_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_1.word_embeddings, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load saved embeddings\n",
    "with open(SAVE_TO + '/en_it_rand_500K_V_dec19.pkl','rb') as f:\n",
    "    C_embedding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... C shape: (20003, 200)\n",
      "... eval IDs should be > 10003: [19065, 10679, 17158, 15613, 13376]\n",
      "... number to eval: 8516\n",
      "... GTT src language: it\n"
     ]
    }
   ],
   "source": [
    "# sanity checks\n",
    "print('... C shape:', C_embedding.shape)\n",
    "print('... eval IDs should be > 10003:', EVAL_IDS[:5])\n",
    "print('... number to eval:', len(EVAL_IDS))\n",
    "print('... GTT src language:', gtt_df.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bilingual Induction Task.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import evaluateBLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Evaluating 8516 'it' Ground Truth Translations\n",
      "... TF graph created for BiW2V model.\n",
      "... TF graph created for BiW2V validation.\n",
      "... finding neighbors...\n",
      "... Done. Total successful translation rate: 0 (92 / 8516)\n"
     ]
    }
   ],
   "source": [
    "src_nbrs, tgt_nbrs = evaluateBLI(C_embedding, vocab, gtt_df, \n",
    "                                 EVAL_IDS, top_k = 10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it_suo :\n",
      ">>> ['it_suo', 'it_un', 'it_proprio', 'it_quale', 'it_questo', 'it_loro', 'it_rito', 'it_momento', 'it_lo', 'it_rara']\n",
      ">>> ['en_his', 'en_her', 'en_marketing', 'en_entertaining', 'en_medalist', 'en_landscape', 'en_violation', 'en_continue', 'en_ruined', 'en_inform']\n"
     ]
    }
   ],
   "source": [
    "# gut check\n",
    "for wrd_id in TEST_WORDS:\n",
    "    try:\n",
    "        idx = EVAL_WORDS.index(wrd_id)\n",
    "    except:\n",
    "        continue\n",
    "    synon = vocab.to_words(src_nbrs[idx])\n",
    "    trans = vocab.to_words(tgt_nbrs[idx])\n",
    "    print(vocab.to_words([wrd_id])[0],\":\")\n",
    "    print(\">>>\", synon)\n",
    "    print(\">>>\", trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Evaluating 2 'it' Ground Truth Translations\n",
      "... TF graph created for BiW2V model.\n",
      "... TF graph created for BiW2V validation.\n",
      "... finding neighbors...\n",
      "it_che ['en_receiver', 'en_outbreak', 'en_phosphate', 'en_who', 'en_potomac', 'en_that', 'en_bohemia', 'en_transition', 'en_sink', 'en_which'] 2 ['en_which', 'en_that', 'en_which', 'en_that'] 1\n",
      "it_suo ['en_entertaining', 'en_ruined', 'en_landscape', 'en_continue', 'en_her', 'en_his', 'en_medalist', 'en_violation', 'en_inform', 'en_marketing'] 1 ['en_his', 'en_his'] 2\n",
      "... Done. Total successful translation rate: 1 (2 / 2)\n"
     ]
    }
   ],
   "source": [
    "# these two words translate correctly\n",
    "src_nbrs, tgt_nbrs = evaluateBLI(C_embedding, vocab, gtt_df, \n",
    "                                 [10010, 10040], top_k = 10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>it_suo</td>\n",
       "      <td>en_his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103642</th>\n",
       "      <td>it_suo</td>\n",
       "      <td>en_his</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            it      en\n",
       "28      it_suo  en_his\n",
       "103642  it_suo  en_his"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# suo (10040) means his/her\n",
    "gtt_df[gtt_df['it'] == 'it_suo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it_che</td>\n",
       "      <td>en_which</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it_che</td>\n",
       "      <td>en_that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103616</th>\n",
       "      <td>it_che</td>\n",
       "      <td>en_which</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103617</th>\n",
       "      <td>it_che</td>\n",
       "      <td>en_that</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            it        en\n",
       "2       it_che  en_which\n",
       "3       it_che   en_that\n",
       "103616  it_che  en_which\n",
       "103617  it_che   en_that"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# che (10010) means which\n",
    "gtt_df[gtt_df['it'] == 'it_che']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: Most Common Target Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... TF graph created for BiW2V model.\n",
      "... TF graph created for BiW2V training.\n",
      "... TF graph created for BiW2V validation.\n"
     ]
    }
   ],
   "source": [
    "from models import BiW2V_mle\n",
    "\n",
    "# create model\n",
    "model_2 = BiW2V_mle(bilingual_dict = translations,\n",
    "                       vocab = vocab, H = EMBEDDING_SIZE)\n",
    "\n",
    "# intialize TF graphs\n",
    "model_2.BuildCoreGraph()\n",
    "model_2.BuildTrainingGraph()\n",
    "model_2.BuildValidationGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fresh data generator\n",
    "DATA_GENERATOR = batch_generator(raw_data, vocab, BATCH_SIZE, WINDOW_SIZE, MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Model Initialized\n",
      "\t <tf.Variable 'Embedding_Layer/ContextEmbeddings:0' shape=(20003, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'Hidden_Layer/WordEmbeddings:0' shape=(20003, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'Hidden_Layer/b:0' shape=(20003,) dtype=float32_ref>\n",
      "... Starting Training\n",
      "... STEP 0 : Average Loss : 0.00252045059204\n",
      "   [en_the] closest:  en_bern, en_mini, it_9, en_trout, en_gather, en_rival, en_homes, it_politica,\n",
      "   [en_last] closest:  it_led, en_idaho, it_funzioni, en_up, it_svevia, it_trascrizione, en_climbing, it_foto,\n",
      "   [it_si] closest:  en_6th, en_batting, en_reporter, en_shortened, it_alpini, it_tecnologie, en_addresses, en_credits,\n",
      "   [it_suo] closest:  en_overhead, en_rico, en_venice, it_provenza, it_raven, it_battezzato, it_fire, it_normativa,\n",
      "... STEP 5000 : Average Loss : 4.71148335021\n",
      "... STEP 10000 : Average Loss : 4.22817595466\n",
      "   [en_the] closest:  en_a, en_to, en_and, en_bern, en_mini, en_in, en_trout, it_politica,\n",
      "   [en_last] closest:  it_led, en_idaho, it_funzioni, en_up, it_trascrizione, it_svevia, en_climbing, it_foto,\n",
      "   [it_si] closest:  en_6th, en_reporter, it_tecnologie, en_batting, it_alpini, it_i, en_cleaning, en_cancelled,\n",
      "   [it_suo] closest:  en_overhead, en_venice, en_rico, it_fire, it_raven, it_provenza, it_niente, it_battezzato,\n",
      "... STEP 15000 : Average Loss : 4.04906350614\n",
      "... STEP 20000 : Average Loss : 4.0758832608\n",
      "   [en_the] closest:  en_a, en_to, en_and, en_in, en_bern, en_mini, en_electric, en_his,\n",
      "   [en_last] closest:  it_led, en_idaho, it_funzioni, en_up, it_svevia, it_trascrizione, it_foto, en_climbing,\n",
      "   [it_si] closest:  it_i, en_6th, en_reporter, it_tecnologie, it_alpini, en_batting, en_cancelled, en_cleaning,\n",
      "   [it_suo] closest:  en_overhead, en_venice, it_di, en_rico, it_fire, it_raven, it_provenza, it_niente,\n",
      "... STEP 25000 : Average Loss : 3.99680838432\n",
      "... STEP 30000 : Average Loss : 3.94877794099\n",
      "   [en_the] closest:  en_a, en_and, en_to, en_his, en_bern, en_in, en_an, en_its,\n",
      "   [en_last] closest:  en_idaho, it_led, it_funzioni, en_up, it_svevia, it_trascrizione, it_foto, en_climbing,\n",
      "   [it_si] closest:  it_i, en_6th, en_reporter, it_tecnologie, it_alpini, en_batting, it_in, en_cancelled,\n",
      "   [it_suo] closest:  it_di, en_overhead, en_venice, it_fire, it_raven, en_rico, it_stato, it_niente,\n",
      "... STEP 35000 : Average Loss : 3.92520805442\n",
      "... STEP 40000 : Average Loss : 3.90608162381\n",
      "   [en_the] closest:  en_a, en_his, en_and, en_its, en_an, en_in, en_bern, en_to,\n",
      "   [en_last] closest:  en_idaho, it_led, it_funzioni, en_up, it_trascrizione, it_svevia, it_foto, en_climbing,\n",
      "   [it_si] closest:  it_i, en_reporter, en_6th, it_tecnologie, it_alpini, it_in, en_batting, en_cancelled,\n",
      "   [it_suo] closest:  it_di, en_overhead, en_venice, it_dopo, it_fire, it_raven, en_rico, it_stato,\n",
      "... STEP 45000 : Average Loss : 3.88112063468\n",
      "... STEP 50000 : Average Loss : 3.82327789607\n",
      "   [en_the] closest:  en_a, en_his, en_its, en_an, en_this, en_and, en_bern, en_electric,\n",
      "   [en_last] closest:  en_idaho, it_led, it_funzioni, en_up, it_trascrizione, it_foto, it_svevia, en_climbing,\n",
      "   [it_si] closest:  it_i, en_reporter, en_6th, it_in, it_tecnologie, it_alpini, en_batting, it_le,\n",
      "   [it_suo] closest:  it_di, en_overhead, en_venice, it_dopo, it_raven, it_fire, it_stato, en_rico,\n",
      "... Training Complete\n",
      "... 50000 batches trained in 156.13361311 seconds\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "start = time.time()\n",
    "model_2.train(nBATCHES, DATA_GENERATOR, TEST_WORDS, learning_rate = ALPHA)\n",
    "tot = (time.time() - start)\n",
    "print('... {} batches trained in {} seconds'.format(nBATCHES, tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# context \n",
    "filename = SAVE_TO + '/en_it_mle_50K_V_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_2.context_embeddings, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# word\n",
    "filename = SAVE_TO + '/en_it_mle_50K_U_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_2.word_embeddings, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load saved embeddings\n",
    "with open(SAVE_TO + '/en_it_mle_50K_V_dec19.pkl','rb') as f:\n",
    "    C_embedding2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... C shape: (20003, 200)\n",
      "... eval IDs should be > 10003: [19065, 10679, 17158, 15613, 13376]\n",
      "... number to eval: 8516\n",
      "... GTT src language: it\n"
     ]
    }
   ],
   "source": [
    "# sanity checks\n",
    "print('... C shape:', C_embedding2.shape)\n",
    "print('... eval IDs should be > 10003:', EVAL_IDS[:5])\n",
    "print('... number to eval:', len(EVAL_IDS))\n",
    "print('... GTT src language:', gtt_df.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bilingual Induction Task.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models import evaluateBLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Evaluating 8516 'it' Ground Truth Translations\n",
      "... TF graph created for BiW2V model.\n",
      "... TF graph created for BiW2V validation.\n",
      "... finding neighbors...\n",
      "... Done. Total successful translation rate: 0 (9 / 8516)\n"
     ]
    }
   ],
   "source": [
    "src_nbrs, tgt_nbrs = evaluateBLI(C_embedding2, vocab, gtt_df, \n",
    "                                 EVAL_IDS, top_k = 10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it_suo :\n",
      ">>> ['it_suo', 'it_di', 'it_dopo', 'it_raven', 'it_fire', 'it_stato', 'it_rito', 'it_niente', 'it_provenza', 'it_dei']\n",
      ">>> ['en_overhead', 'en_venice', 'en_rico', 'en_medalist', 'en_papua', 'en_consciousness', 'en_spoken', 'en_suspicious', 'en_tempo', 'en_society']\n"
     ]
    }
   ],
   "source": [
    "# gut check\n",
    "for wrd_id in TEST_WORDS:\n",
    "    try:\n",
    "        idx = EVAL_WORDS.index(wrd_id)\n",
    "    except:\n",
    "        continue\n",
    "    synon = vocab.to_words(src_nbrs[idx])\n",
    "    trans = vocab.to_words(tgt_nbrs[idx])\n",
    "    print(vocab.to_words([wrd_id])[0],\":\")\n",
    "    print(\">>>\", synon)\n",
    "    print(\">>>\", trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3: Closest Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... TF graph created for BiW2V model.\n",
      "... TF graph created for BiW2V training.\n",
      "... TF graph created for BiW2V validation.\n"
     ]
    }
   ],
   "source": [
    "from models import BiW2V_nn\n",
    "\n",
    "# create model\n",
    "model_3 = BiW2V_nn(bilingual_dict = translations,\n",
    "                   vocab = vocab, H = EMBEDDING_SIZE)\n",
    "\n",
    "# intialize TF graphs\n",
    "model_3.BuildCoreGraph()\n",
    "model_3.BuildTrainingGraph()\n",
    "model_3.BuildValidationGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fresh data generator\n",
    "DATA_GENERATOR = batch_generator(raw_data, vocab, BATCH_SIZE, WINDOW_SIZE, MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Model Initialized\n",
      "\t <tf.Variable 'Embedding_Layer/ContextEmbeddings:0' shape=(20003, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'Hidden_Layer/WordEmbeddings:0' shape=(20003, 200) dtype=float32_ref>\n",
      "\t <tf.Variable 'Hidden_Layer/b:0' shape=(20003,) dtype=float32_ref>\n",
      "... Starting Training\n",
      "... STEP 0 : Average Loss : 0.02340858078\n",
      "   [en_the] closest:  en_nutrition, it_ma, en_prolonged, it_falco, it_vercelli, en_artists, en_beliefs, it_idraulico,\n",
      "   [en_last] closest:  en_earn, en_renowned, it_decadimento, it_boy, en_korea, en_basement, en_resulting, en_told,\n",
      "   [it_si] closest:  en_qualities, it_generato, it_scuole, en_employer, en_situation, en_chorus, en_to, en_inadequate,\n",
      "   [it_suo] closest:  en_sat, it_rimpiazzare, en_playing, it_triangolare, it_realmente, en_profile, it_tutta, it_stirpe,\n",
      "... STEP 500 : Average Loss : 6.30888293695\n",
      "... STEP 1000 : Average Loss : 5.52120716763\n",
      "   [en_the] closest:  en_nutrition, en_artists, it_falco, it_ma, en_beliefs, it_saturno, it_anime, it_siccità,\n",
      "   [en_last] closest:  en_earn, en_renowned, it_decadimento, it_boy, en_korea, en_basement, en_resulting, en_told,\n",
      "   [it_si] closest:  en_qualities, it_generato, it_scuole, en_to, en_employer, en_chorus, en_situation, en_inadequate,\n",
      "   [it_suo] closest:  en_sat, it_rimpiazzare, en_playing, it_triangolare, it_realmente, it_tutta, en_profile, en_spirits,\n",
      "... STEP 1500 : Average Loss : 5.36810376883\n",
      "... STEP 2000 : Average Loss : 5.16852718353\n",
      "   [en_the] closest:  en_nutrition, en_artists, it_falco, it_ma, en_beliefs, it_saturno, it_siccità, it_anime,\n",
      "   [en_last] closest:  en_earn, en_renowned, it_decadimento, it_boy, en_korea, en_basement, en_resulting, en_told,\n",
      "   [it_si] closest:  en_qualities, it_scuole, it_generato, en_to, en_employer, en_chorus, en_situation, en_inadequate,\n",
      "   [it_suo] closest:  en_sat, it_rimpiazzare, en_playing, it_triangolare, it_tutta, it_realmente, en_profile, en_spirits,\n",
      "... STEP 2500 : Average Loss : 5.13391390038\n",
      "... STEP 3000 : Average Loss : 5.07301244187\n",
      "   [en_the] closest:  en_nutrition, en_artists, it_falco, it_ma, it_saturno, it_siccità, en_beliefs, en_bengal,\n",
      "   [en_last] closest:  en_renowned, en_earn, it_decadimento, it_boy, en_korea, en_basement, en_resulting, en_told,\n",
      "   [it_si] closest:  en_qualities, en_to, it_scuole, it_generato, en_employer, en_chorus, en_situation, en_inadequate,\n",
      "   [it_suo] closest:  en_sat, it_rimpiazzare, en_playing, it_tutta, it_triangolare, it_realmente, en_profile, en_spirits,\n",
      "... STEP 3500 : Average Loss : 5.01885948992\n",
      "... STEP 4000 : Average Loss : 5.05571406984\n",
      "   [en_the] closest:  en_nutrition, en_a, en_artists, it_falco, it_ma, it_siccità, en_bengal, it_anime,\n",
      "   [en_last] closest:  en_earn, en_renowned, it_decadimento, it_boy, en_korea, en_basement, en_resulting, en_turin,\n",
      "   [it_si] closest:  en_qualities, en_to, it_scuole, en_employer, it_generato, en_chorus, en_situation, en_inadequate,\n",
      "   [it_suo] closest:  en_sat, it_rimpiazzare, en_playing, it_tutta, it_triangolare, it_realmente, en_profile, en_spirits,\n",
      "... STEP 4500 : Average Loss : 4.97535962629\n",
      "... STEP 5000 : Average Loss : 4.9615819416\n",
      "   [en_the] closest:  en_nutrition, en_a, it_falco, en_artists, it_ma, en_bengal, it_siccità, it_anime,\n",
      "   [en_last] closest:  en_renowned, en_earn, it_decadimento, it_boy, en_korea, en_basement, en_resulting, en_turin,\n",
      "   [it_si] closest:  en_qualities, en_to, it_scuole, en_employer, it_generato, en_chorus, en_preston, it_sceso,\n",
      "   [it_suo] closest:  en_sat, it_rimpiazzare, en_playing, it_tutta, it_realmente, it_triangolare, en_profile, en_spirits,\n",
      "... Training Complete\n",
      "... 5000 batches trained in 1766.22677398 seconds\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "nBATCHES = 5000 # Takes too long w/ nn so we'll only do 5K\n",
    "start = time.time()\n",
    "model_3.train(nBATCHES, DATA_GENERATOR, TEST_WORDS, learning_rate = ALPHA)\n",
    "tot = (time.time() - start)\n",
    "print('... {} batches trained in {} seconds'.format(nBATCHES, tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# context \n",
    "filename = SAVE_TO + '/en_it_nn_5K_V_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_2.context_embeddings, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# word\n",
    "filename = SAVE_TO + '/en_it_nn_5K_U_dec19.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(model_2.word_embeddings, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load saved embeddings\n",
    "with open(SAVE_TO + '/en_it_nn_5K_V_dec19.pkl','rb') as f:\n",
    "    C_embedding3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... C shape: (20003, 200)\n",
      "... eval IDs should be > 10003: [19065, 10679, 17158, 15613, 13376]\n",
      "... number to eval: 8516\n",
      "... GTT src language: it\n"
     ]
    }
   ],
   "source": [
    "# sanity checks\n",
    "print('... C shape:', C_embedding3.shape)\n",
    "print('... eval IDs should be > 10003:', EVAL_IDS[:5])\n",
    "print('... number to eval:', len(EVAL_IDS))\n",
    "print('... GTT src language:', gtt_df.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bilingual Induction Task.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models import evaluateBLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Evaluating 8516 'it' Ground Truth Translations\n",
      "... TF graph created for BiW2V model.\n",
      "... TF graph created for BiW2V validation.\n",
      "... finding neighbors...\n",
      "... Done. Total successful translation rate: 0 (9 / 8516)\n"
     ]
    }
   ],
   "source": [
    "src_nbrs, tgt_nbrs = evaluateBLI(C_embedding3, vocab, gtt_df, \n",
    "                                 EVAL_IDS, top_k = 10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it_suo :\n",
      ">>> ['it_suo', 'it_di', 'it_dopo', 'it_raven', 'it_fire', 'it_stato', 'it_rito', 'it_niente', 'it_provenza', 'it_dei']\n",
      ">>> ['en_overhead', 'en_venice', 'en_rico', 'en_medalist', 'en_papua', 'en_consciousness', 'en_spoken', 'en_suspicious', 'en_tempo', 'en_society']\n"
     ]
    }
   ],
   "source": [
    "# gut check\n",
    "for wrd_id in TEST_WORDS:\n",
    "    try:\n",
    "        idx = EVAL_WORDS.index(wrd_id)\n",
    "    except:\n",
    "        continue\n",
    "    synon = vocab.to_words(src_nbrs[idx])\n",
    "    trans = vocab.to_words(tgt_nbrs[idx])\n",
    "    print(vocab.to_words([wrd_id])[0],\":\")\n",
    "    print(\">>>\", synon)\n",
    "    print(\">>>\", trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
